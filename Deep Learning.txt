***** Some deep learning concept:
--------------------------------------
--------------------------------------


*** Activation function, Accuracy matrix, Loss function, Optimizer.


=> Activation function:
	1) Sigmoid: Use in binary class classification in output layers.
	2) Softmax: Use in multi class classification in output layers.
	3) Relu : Use convolational network and fully connected layer in input or hidden layer.

=> Loss Function:
	1) BinaryCrossentropy: Use for binary classification.
	2) CategoricalCrossentropy: Use multi class classification.

=> Accuracy Matrix:
	1) Accuracy: Use in different classification.

=> Optimizer:
	1) SGD, RMSprop, Adam, Adadelta, Adagard, Adamax

*** Fully connected neural network always take only one dimantional input.

*** Why use Polling Layers:
-----------------------------
Answer: Why to use Pooling Layers? Pooling layers are used to reduce the dimensions of the feature maps. Thus, it reduces the number of parameters to learn and the amount of computation performed in the network. The pooling layer summarises the features present in a region of the feature map generated by a convolution layer.